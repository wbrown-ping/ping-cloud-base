########################################################################################################################
# This file provides sample patches to update the following settings for each provisioned app:
#
#   - HPA min/max replicas and target CPU utilization
#   - Memory/CPU requests/limits
#   - Disk size
#   - Execute PGO database restore
#
# It serves just as a sample and not included from any kustomization.yaml file. PS/GSO must update the
# custom-patches.yaml file using these snippets as appropriate for a customer environment for it to be effective.
########################################################################################################################


################################################
#               Nginx public
################################################

### Update public nginx HPA min/max replicas and target CPU utilization ###
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx-public
spec:
  minReplicas: 3
  maxReplicas: 3
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-ingress-controller
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---

### Update the header size max for customers needing larger sized cookies/headers ###
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-configuration
  namespace: ingress-nginx-private
data:
  large_client_header_buffers: "4 128k"

---

### Update the header size max for customers needing larger sized cookies/headers ###
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-configuration
  namespace: ingress-nginx-public
data:
  large_client_header_buffers: "4 128k"

---

################################################
#              Nginx private
################################################

### Update private nginx HPA min/max replicas and target CPU utilization ###
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx-private
spec:
  minReplicas: 1
  maxReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-ingress-controller
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---

################################################
#                Logstash
################################################

### Update logstash replicas count

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: logstash-elastic
spec:
  minReplicas: 1
  maxReplicas: 6
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: logstash-elastic

---

### Update logstash replicas count and adjust resources

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: logstash-elastic
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: logstash-elastic
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: AverageValue
        averageValue: "1.7"
  - type: Resource
    resource:
      name: memory
      target:
        type: AverageValue
        averageValue: 3.7Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: logstash-elastic
  namespace: elastic-stack-logging
spec:
  template:
    spec:
      containers:
        - name: logstash
          resources:
            limits:
              cpu: "2"
              memory: 4Gi
            requests:
              cpu: "1"
              memory: 2Gi
          env:
            - name: LS_JAVA_OPTS
              value: '-Xms3500m -Xmx3500m'
            - name: PIPELINE_WORKERS
              value: "2"
---
################################################
#                OpenSearch
################################################

# Increase Disk Size
apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: opensearch-cluster
spec:
  nodePools:
    - component: hot
      diskSize: "500Gi"
---
# Increase CPU resources
apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: opensearch-cluster
spec:
  nodePools:
    - component: hot
      resources:
        requests:
          cpu: "3"
        limits:
          cpu: "6"
---
# Increase Memory Resources
apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: opensearch-cluster
spec:
  nodePools:
    - component: hot
      jvm: -Xmx5g -Xms5g
      resources:
        requests:
          memory: 6Gi
        limits:
          memory: 6Gi

---
# Scale opensearch replicas
apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: opensearch-cluster
spec:
  nodePools:
    - component: hot
      replicas: 5 # Scale down is not supported

################################################
#                End Opensearch patches.
################################################
---

################################################
#               PingAccess-WAS
################################################

### Update pingaccess-was-admin disk size, memory/cpu requests/limits ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingaccess-was-admin
  namespace: ping-cloud
spec:
  volumeClaimTemplates:
  - metadata:
      name: out-dir
      labels:
        app: ping-cloud
      annotations:
        # This annotation is required to prevent volume-autoscaler to resize this volume
        volume.autoscaler.kubernetes.io/ignore: "true"
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: pingaccess-was-gp3
      resources:
        requests:
          storage: 20Gi
  template:
    spec:
      containers:
      - name: pingaccess-was-admin
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update pingaccess-was engine replicas, memory/cpu requests/limits  ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingaccess-was
  namespace: ping-cloud
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: pingaccess-was
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update the PingAccess-WAS engine's proxy body size ###
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: pingaccess-was-ingress
  namespace: ping-cloud
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 16m

---

### Update pingaccess-was backup cronjob to adjust schedule
apiVersion: batch/v1
kind: CronJob
metadata:
  name: pingaccess-was-periodic-backup
  namespace: ping-cloud
spec:
  schedule: "0 * * * *"

---

################################################
#                PingAccess
################################################

### Update pingaccess-admin disk size, memory/cpu requests/limits ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingaccess-admin
  namespace: ping-cloud
spec:
  volumeClaimTemplates:
  - metadata:
      name: out-dir
      labels:
        app: ping-cloud
      annotations:
        # This annotation is required to prevent volume-autoscaler to resize this volume
        volume.autoscaler.kubernetes.io/ignore: "true"
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: pingaccess-gp3
      resources:
        requests:
          storage: 20Gi
  template:
    spec:
      containers:
      - name: pingaccess-admin
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update pingaccess engine memory/cpu requests/limits  ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingaccess
  namespace: ping-cloud
spec:
  template:
    spec:
      containers:
      - name: pingaccess
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update pingaccess engine HPA min/max replicas and target CPU utilization ###
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pingaccess
  namespace: ping-cloud
spec:
  minReplicas: 1
  maxReplicas: 2
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: pingaccess
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---

### Update pingaccess-was engine HPA min/max replicas and target CPU utilization ###
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pingaccess-was
  namespace: ping-cloud
spec:
  minReplicas: 1
  maxReplicas: 2
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: pingaccess-was
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---

### Update pingaccess backup cronjob to adjust schedule
apiVersion: batch/v1
kind: CronJob
metadata:
  name: pingaccess-periodic-backup
  namespace: ping-cloud
spec:
  schedule: "0 * * * *"

---

################################################
#                Karpenter
################################################
### The karpenter will stay disabled until all customers have been upgraded.
### Scale down cluster-autoscaler replicas to zero
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 0

---

################################################
#                ArgoCD
################################################
# The custom logging verbosity level for the below pods is added. So we donâ€™t need to implement it from scratch.

# argocd-dex-server
# argocd-repo-server (only git-ops-command container)

# Added a patch for the above pods in k8s-configs/cluster-tools/base/git-ops/argo/kustomization.yaml file. 
# If we want to change the logging level change the inline in command to one of  debug|info|warn|error
apiVersion: apps/v1
kind: Deployment
metadata:
  name: argocd-dex-server
spec:
  template:
    spec:
      containers:
      - name: dex
        command:
        - sh
        - -c
        - /shared/argocd-dex rundex --loglevel error
---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: argocd-repo-server
spec:
  template:
    spec:
      containers:
      - name: git-ops-command
        command: 
        - sh
        - -c
        - /var/run/argocd/argocd-cmp-server --loglevel error

---

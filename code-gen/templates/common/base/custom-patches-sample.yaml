########################################################################################################################
# This file provides sample patches to update the following settings for each provisioned app:
#
#   - HPA min/max replicas and target CPU utilization
#   - Memory/CPU requests/limits
#   - Disk size
#   - Execute PGO database restore
#
# It serves just as a sample and not included from any kustomization.yaml file. PS/GSO must update the
# custom-patches.yaml file using these snippets as appropriate for a customer environment for it to be effective.
########################################################################################################################


################################################
#               Nginx public
################################################

### Update public nginx HPA min/max replicas and target CPU utilization ###
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx-public
spec:
  minReplicas: 3
  maxReplicas: 3
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-ingress-controller
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---

### Update the header size max for customers needing larger sized cookies/headers ###
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-configuration
  namespace: ingress-nginx-private
data:
  large_client_header_buffers: "4 128k"

---

### Update the header size max for customers needing larger sized cookies/headers ###
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-configuration
  namespace: ingress-nginx-public
data:
  large_client_header_buffers: "4 128k"

---

################################################
#              Nginx private
################################################

### Update private nginx HPA min/max replicas and target CPU utilization ###
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx-private
spec:
  minReplicas: 1
  maxReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-ingress-controller
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---

################################################
#                Logstash
################################################

### Update logstash replicas count

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: logstash-elastic
spec:
  minReplicas: 1
  maxReplicas: 6
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: logstash-elastic

---

### Update logstash replicas count and adjust resources

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: logstash-elastic
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: logstash-elastic
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: AverageValue
        averageValue: "1.7"
  - type: Resource
    resource:
      name: memory
      target:
        type: AverageValue
        averageValue: 3.7Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: logstash-elastic
  namespace: elastic-stack-logging
spec:
  template:
    spec:
      containers:
        - name: logstash
          resources:
            limits:
              cpu: "2"
              memory: 4Gi
            requests:
              cpu: "1"
              memory: 2Gi
          env:
            - name: LS_JAVA_OPTS
              value: '-Xms3500m -Xmx3500m'
            - name: PIPELINE_WORKERS
              value: "2"
---
# Update logstash to use a customer pipeline configuration from configMap, overriding image defaults
# Be sure to replace <replace-me> with the appropriate value for your configuration file, it can be input, filter, or output
# but needs to match one of the following options:
# - 01-input.conf
# - 02-filters.conf
# - 03-outputs.conf
#
# Also be sure to correctly replace the contents of the volume and volumeMounts sections with the appropriate
# values for your configMap, which can be defined in custom-resources directory.
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: logstash-elastic
spec:
  template:
    spec:
      containers:
      - name: logstash
        volumeMounts:
        - name: customer-pipeline-custom
          mountPath: /usr/share/logstash/pipeline/customer/<replace-me>.conf
          subPath: <replace-me>.conf
      volumes:
      - name: customer-pipeline-custom
        configMap:
          name: customer-pipeline-custom
          items:
          - key: <name-of-your-data-entry>.conf
            path: <name-of-your-data-entry>.conf

---          

# Corresponding configMap for above logstash patch.  
# Replace the data section with the contents of the customer pipeline configuration file.
# You will also need to name the data entries to be match the existing file on image.  Options are below
# and depend on if you are trying to overwrite the input, filter, or output:
#  - input.conf
#  - filter.conf
#  - output.conf
apiVersion: v1
kind: ConfigMap
metadata:
  name: customer-pipeline-custom
data:
  <replace-me>.conf: |
    # Paste the contents of your logstash config here
    {
      "key": "value"
    }
################################################
#                OpenSearch
################################################

# Increase Disk Size
apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: opensearch-cluster
spec:
  nodePools:
    - component: hot
      diskSize: "500Gi"
    - component: warm
      diskSize: "500Gi"
---
# Increase CPU resources
apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: opensearch-cluster
spec:
  nodePools:
    - component: hot
      resources:
        requests:
          cpu: "3"
        limits:
          cpu: "6"
    - component: warm
      resources:
        requests:
          cpu: "2"
        limits:
          cpu: "4"
---
# Increase Memory Resources
apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: opensearch-cluster
spec:
  nodePools:
    - component: hot
      jvm: -Xmx5g -Xms5g
      resources:
        requests:
          memory: 6Gi
        limits:
          memory: 6Gi
    - component: warm
      jvm: -Xmx5g -Xms5g
      resources:
        requests:
          memory: 6Gi
        limits:
          memory: 6Gi

---
# Scale opensearch replicas
apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: opensearch-cluster
spec:
  nodePools:
    - component: hot
      replicas: 5 # Scale down is not supported
    - component: warm
      replicas: 3

################################################
#                End Opensearch patches.
################################################
---
################################################
#                PingDirectory
################################################

### Update pingdirectory disk size, replicas, memory/cpu requests/limits  ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingdirectory
  namespace: ping-cloud
spec:
  replicas: 3
  volumeClaimTemplates:
  - metadata:
      name: out-dir
      labels:
        app: ping-cloud
        role: pingdirectory
        class: pingdirectory-server
      annotations:
        # This annotation is required to prevent volume-autoscaler to resize this volume
        volume.autoscaler.kubernetes.io/ignore: "true"
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: pingdirectory-gp3
      resources:
        requests:
          storage: 40Gi
  template:
    spec:
      containers:
      - name: pingdirectory
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

################################################
#               PingAccess-WAS
################################################

### Update pingaccess-was-admin disk size, memory/cpu requests/limits ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingaccess-was-admin
  namespace: ping-cloud
spec:
  volumeClaimTemplates:
  - metadata:
      name: out-dir
      labels:
        app: ping-cloud
      annotations:
        # This annotation is required to prevent volume-autoscaler to resize this volume
        volume.autoscaler.kubernetes.io/ignore: "true"
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: pingaccess-was-gp3
      resources:
        requests:
          storage: 20Gi
  template:
    spec:
      containers:
      - name: pingaccess-was-admin
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update pingaccess-was engine replicas, memory/cpu requests/limits  ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingaccess-was
  namespace: ping-cloud
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: pingaccess-was
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update the PingAccess-WAS engine's proxy body size ###
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: pingaccess-was-ingress
  namespace: ping-cloud
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 16m

---

### Update pingaccess-was backup cronjob to adjust schedule
apiVersion: batch/v1
kind: CronJob
metadata:
  name: pingaccess-was-periodic-backup
  namespace: ping-cloud
spec:
  schedule: "0 * * * *"

---
################################################
#                PingFederate
################################################

### Update pingfederate-admin disk size, memory/cpu requests/limits ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingfederate-admin
  namespace: ping-cloud
spec:
  volumeClaimTemplates:
  - metadata:
      name: out-dir
      labels:
        app: ping-cloud
      annotations:
        # This annotation is required to prevent volume-autoscaler to resize this volume
        volume.autoscaler.kubernetes.io/ignore: "true"
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: pingfederate-gp3
      resources:
        requests:
          storage: 20Gi
  template:
    spec:
      containers:
      - name: pingfederate-admin
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update pingfederate engine memory/cpu requests/limits  ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingfederate
  namespace: ping-cloud
spec:
  template:
    spec:
      containers:
      - name: pingfederate
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update pingfederate engine HPA min/max replicas and target CPU utilization ###
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pingfederate
  namespace: ping-cloud
spec:
  minReplicas: 1
  maxReplicas: 2
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: pingfederate
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---

### Update pingfederate backup cronjob to adjust schedule
apiVersion: batch/v1
kind: CronJob
metadata:
  name: pingfederate-periodic-backup
  namespace: ping-cloud
spec:
  schedule: "0 * * * *"

---

################################################
#                PingAccess
################################################

### Update pingaccess-admin disk size, memory/cpu requests/limits ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingaccess-admin
  namespace: ping-cloud
spec:
  volumeClaimTemplates:
  - metadata:
      name: out-dir
      labels:
        app: ping-cloud
      annotations:
        # This annotation is required to prevent volume-autoscaler to resize this volume
        volume.autoscaler.kubernetes.io/ignore: "true"
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: pingaccess-gp3
      resources:
        requests:
          storage: 20Gi
  template:
    spec:
      containers:
      - name: pingaccess-admin
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update pingaccess engine memory/cpu requests/limits  ###
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pingaccess
  namespace: ping-cloud
spec:
  template:
    spec:
      containers:
      - name: pingaccess
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
            cpu: "1"

---

### Update pingaccess engine HPA min/max replicas and target CPU utilization ###
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pingaccess
  namespace: ping-cloud
spec:
  minReplicas: 1
  maxReplicas: 2
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: pingaccess
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---

### Update pingaccess-was engine HPA min/max replicas and target CPU utilization ###
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pingaccess-was
  namespace: ping-cloud
spec:
  minReplicas: 1
  maxReplicas: 2
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: pingaccess-was
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---

### Update pingaccess backup cronjob to adjust schedule
apiVersion: batch/v1
kind: CronJob
metadata:
  name: pingaccess-periodic-backup
  namespace: ping-cloud
spec:
  schedule: "0 * * * *"

---

################################################
#           PingFederate Provisioning
################################################

### Update pingfederate provisioning db disk size, replicas, memory/cpu requests  ###
apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: pf-provisioning
spec:
  instances:
    # Must specify entire instance definition because CRD replaces instead of merges list item
    - name: instance1
      metadata:
        annotations:
          # This annotation is required to prevent volume-autoscaler to resize this volume
          volume.autoscaler.kubernetes.io/ignore: "true"
      replicas: 3
      minAvailable: 1
      resources:
        limits:
          cpu: 2
          memory: 4Gi
        requests:
          cpu: 2
          memory: 2Gi
      dataVolumeClaimSpec:
        storageClassName: pgo-gp3
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: 20Gi
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: role
                      operator: In
                      values:
                        - pf-provisioning
                topologyKey: "topology.kubernetes.io/zone"

---

################################################
#                Postgres-Operator
################################################

### Execute a PGO database restore for pf-provisioning
### ***NOTE: This action will bring down the database until the restoration is complete!***
### If this has been executed before, the id number will need to be incremented to kick off a new restore job
apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: pf-provisioning
  annotations:
    postgres-operator.crunchydata.com/pgbackrest-restore: id1

---

################################################
#                Karpenter
################################################
### The karpenter will stay disabled until all customers have been upgraded.
### Scale down cluster-autoscaler replicas to zero
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 0

---

################################################
#                ArgoCD
################################################
# The custom logging verbosity level for the below pods is added. So we don’t need to implement it from scratch.

# argocd-dex-server
# argocd-repo-server (only git-ops-command container)

# Added a patch for the above pods in k8s-configs/cluster-tools/base/git-ops/argo/kustomization.yaml file. 
# If we want to change the logging level change the inline in command to one of  debug|info|warn|error
apiVersion: apps/v1
kind: Deployment
metadata:
  name: argocd-dex-server
spec:
  template:
    spec:
      containers:
      - name: dex
        command:
        - sh
        - -c
        - /shared/argocd-dex rundex --loglevel error
---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: argocd-repo-server
spec:
  template:
    spec:
      containers:
      - name: git-ops-command
        command: 
        - sh
        - -c
        - /var/run/argocd/argocd-cmp-server --loglevel error

---
